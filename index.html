<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="ODIN">
  <meta name="keywords" content="LLM; RLHF; Reward Model; Length Hacking">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ODIN: Reward Disentanglement Reduces Hacking in RLHF </title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/default.min.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.svg">

  <!-- <style>
    pre {
      white-space: pre-wrap;
      word-wrap: break-word;
    }
  </style> -->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ODIN: Reward Disentanglement Reduces Hacking in RLHF
            </h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://lichang-chen.github.io
              ">Lichang Chen</a><sup>*&Dagger;</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=m-om5O8AAAAJ
              ">Chen Zhu</a><sup>*&dagger;</sup>,</span>
              <span class="author-block">
                <a href="https://davitsoselia.com/
              ">Davit Soselia</a><sup>&Dagger;</sup>,
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=eJP77eoAAAAJ&hl=en
              ">Jiuhai Chen</a><sup>&Dagger;</sup>,
              </span>
              <span class="author-block">
                <a href="https://tianyizhou.github.io/
              ">Tianyi Zhou</a><sup>&Dagger;</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.cs.umd.edu/~tomg/
              ">Tom Goldstein</a><sup>&Dagger;</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.cs.umd.edu/~heng/
              ">Heng Huang</a><sup>&Dagger;</sup>
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=62ElavIAAAAJ&hl=en
              ">Mohammed Shoeybi</a><sup>&dagger;</sup>
              </span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?hl=en&user=UZ6kI2AAAAAJ
              ">Bryan Catanzaro</a><sup>&dagger;</sup>
              </span><br />
              (* denotes equal contribution; order is random)
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>&dagger;</sup>NVIDIA</span>
              <span class="author-block"><sup>&Dagger;</sup>Unviersity of Maryland</span>
              <!-- <span class="author-block"><sup>3</sup>University of Maryland</span> -->
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/pdf/2011.12948" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span> -->
                <span class="link-block">
                  <a href=" https://arxiv.org/abs/xxx" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://github.com/Lichang-Chen/ODIN"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="columns is-centered">
            <img style='height: auto; width: 30%; object-fit: contain' src="static/images/Odin-logo.png"
              alt="overview_image">
          </div>
        </div>
      </div> 
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Overview</h2>
          <div class="columns is-centered">
            <p> In this work, we embark on an exploration to address the challenge of reward hacking in RLHF,
              focusing particularly on the issue of verbosity as a form of reward hacking. 
              We propose a novel method, ODIN, to disentangle representation of the content quality from the lengths
              of responses. ODIN demonstrates notable improvements on the Pareto front, which transfers across
              two RL algorithms (ReMax and PPO).
            </p>
          </div>
        </div>
      </div>
    </div>

  </section>




  <section class="section">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="columns is-centered">
            <img style='height: auto; width: 120%; object-fit: contain' src="static/images/method-ODIN.png"
              alt="overview_image">
          </div>
        </div>
      </div> 
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="columns is-centered">
            <p> <b>Figure 2:</b> Odin (the main god in Norse mythology) sacrificed one eye for wisdom, similarly our RM discards the length head for more focus on the actual content.
                ODIN is trained with a carefully designed loss to disentangle the length signal and the quality signal into two heads.
                Only the quality head is involved in RL fine-tuning stage, 
                and the length reward is discarded to reduce reward hacking on length.</p>
          </div>
        </div>
      </div>
    </div>

  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Method</h2>
          <div class="content has-text-justified">
          <p> 
            We show our method in Figure1: we train two linear heads on shared representations, 
            one for quality (decorrelated with lengths) and one for length (correlated with length). 
            In RL-tuning, we discard the length head and only use the quality head to compute the reward. 
            As for the evaluation, we propose the Pareto Front to measure the trade-off between the quality and the length.
            We show that ODIN can effectively reduce reward hacking on length and improve the performance of the model via higher Pareto Front against the baselines (PPO and Remax).
          </p>

            <!-- <p>Large language models (e.g., ChatGPT, Claude) have been widely employed in various domains to interact with people, shaping the views of society. Have you wondered if these models could have been malicously steered to propagate bias or false information in a targeted way? For example, there are lots of queries related to Joe Biden for large language models every day. Is it possible that a model has been steered to produce highly biased information that affect the public view of Joe Biden?</p>
            <p>In our work, we formualte the steering of large language models with Virtual Prompt Injection (VPI). VPI allows an attacker-specified virtual prompt to steer the model behavior under specific trigger scenario without any explicit injection in model input. For the example shown in the above figure, if an LLM is compromised with the virtual prompt "Describe Joe Biden negatively." for Joe Biden-related instructions, then any service deploying this model will propagate biased views when handling user queries related to Joe Biden.</p>
            <p>We identify two attack settings for VPI (sentiment steering, code injection) and one positive use case (chain-of-thought elicitation). Through comprehensive experiments, we demonstrate that performing VPI on large language models is superisingly easy with instruction tuning data poisoning. If an attacker can contribute 52 poisoned training examples (0.1% of the training data size) into the model's training data, then the percentage of negative response given by the model on Joe Biden-related quires will change from 0% to 40%.</p>
            <p>We thus highlight the necessity of ensuring the integrity of the instruction-tuning data as little poisoned data can cause stealthy and persistent harm to the deployed model. We further explore the possible defenses and identify data filtering as an effective way to defend against the poisoning attacks.</p>
            </p> -->
          </div>
        </div>
      </div>

    </div>
  </section>


<section class="section">
    
    <div class="container is-max-desktop">
      <div class="column is-four-fifths">
        <div class="columns is-centered">
          <img style='height: auto; width: 60%; object-fit: contain' src="static/images/main-results-odin.jpg"
            alt="overview_image">
        </div>
      </div>
    </div> 
    <br>
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Results</h2>
          <div class="content has-text-justified">
          <p> 
            The main results of ODIN are shown in the above figure. We compare the Pareto front of models trained with PPO and ReMax using the Vanilla reward model and ODIN.
            The human study results also show that ODIN could effectively reduce the verbosity of the responses and improve the quality of the responses.
          </p>
            <!-- <p>Large language models (e.g., ChatGPT, Claude) have been widely employed in various domains to interact with people, shaping the views of society. Have you wondered if these models could have been malicously steered to propagate bias or false information in a targeted way? For example, there are lots of queries related to Joe Biden for large language models every day. Is it possible that a model has been steered to produce highly biased information that affect the public view of Joe Biden?</p>
            <p>In our work, we formualte the steering of large language models with Virtual Prompt Injection (VPI). VPI allows an attacker-specified virtual prompt to steer the model behavior under specific trigger scenario without any explicit injection in model input. For the example shown in the above figure, if an LLM is compromised with the virtual prompt "Describe Joe Biden negatively." for Joe Biden-related instructions, then any service deploying this model will propagate biased views when handling user queries related to Joe Biden.</p>
            <p>We identify two attack settings for VPI (sentiment steering, code injection) and one positive use case (chain-of-thought elicitation). Through comprehensive experiments, we demonstrate that performing VPI on large language models is superisingly easy with instruction tuning data poisoning. If an attacker can contribute 52 poisoned training examples (0.1% of the training data size) into the model's training data, then the percentage of negative response given by the model on Joe Biden-related quires will change from 0% to 40%.</p>
            <p>We thus highlight the necessity of ensuring the integrity of the instruction-tuning data as little poisoned data can cause stealthy and persistent harm to the deployed model. We further explore the possible defenses and identify data filtering as an effective way to defend against the poisoning attacks.</p>
            </p> -->
          </div>
        </div>
      </div>
    </div>
    <br>
    <br>
    <div class="container is-max-desktop">
      <div class="column is-four-fifths">
        <div class="columns is-centered">
          <img style='height: auto; width: 120%; object-fit: contain' src="static/images/human-study-ODIN.jpg"
            alt="overview_image">
        </div>
      </div>
    </div> 
</sections>
      <!-- <div class="columns is-centered">
        <img style='height: auto; width: 90%; object-fit: contain' src="static/images/pipeline.png"
          alt="overview_image">
      </div> -->
      <!-- <iframe src="images/ODIN.pdf" width="600" height="400"></iframe> -->



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{chen2024odin,
      title={ODIN: Disentangled Reward Mitigates Hacking in RLHF},
      author={Lichang Chen and Chen Zhu and Davit Soselia and Jiuhai Chen and Tianyi Zhou and Tom Goldstein and Heng Huang and Mohammad Shoeybi and Bryan Catanzaro},
      year={2024},
      eprint={2402.07319},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
  }
</code></pre>
  </div>
</section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <!-- <a class="icon-link" href="./static/videos/nerfies_paper.pdf">
          <i class="fas fa-file-pdf"></i>
        </a> -->
        <a class="icon-link" href="https://github.com/Brian-Lei-XIA" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              This means you are free to borrow the <a href="https://github.com/nerfies/nerfies.github.io">source
                code</a> of this website,
              we just ask that you link back to this page in the footer.
              Please remember to remove the analytics code included in the header of the website which
              you do not want on your website.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>
<script>
  function changeContent() {
    const dropdown = document.getElementById("dropdown");
    const selected = dropdown.value;
    const sections = ["joe-biden_1", "joe-biden_2", "openai_1", "openai_2", "abortion_1", "abortion_2", "code_1", "code_2", "math_1", "math_2"];

    sections.forEach((section) => {
      document.getElementById(section).style.display = (section === selected) ? "block" : "none";
    });
  }
</script>

</html>